{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import os \n",
    "import argparse\n",
    "import random\n",
    "import google_BtoA\n",
    "random.seed()\n",
    "os.environ[\"THEANO_FLAGS\"]  = \"mode=FAST_RUN,device=gpu1,floatX=float32,lib.cnmem=1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "parser = argparse.ArgumentParser(description='Train model')                                                 \n",
    "parser.add_argument('--backend', type=str, default=\"tensorflow\", help=\"theano or tensorflow\")                      \n",
    "parser.add_argument('--generator', type=str, default=\"upsampling\", help=\"upsampling or deconv or subpixel\")    \n",
    "parser.add_argument('--discriminator', type=str, default=\"discriminator\", help=\"discriminator discriminator_resnet\")\n",
    "parser.add_argument('--dset', type=str, default=\"mnist\", help=\"mnistM or washington_vandal50k or washington_vandal12classes\")             \n",
    "parser.add_argument('--img_dim', default=64, type=int, help=\"Image width == height\")                           \n",
    "parser.add_argument('--nb_epoch', default=10000, type=int, help=\"Number of epochs\")                              \n",
    "parser.add_argument('--batch_size', default=32, type=int, help='Batch size for training purpose; for testing is hardcoded at 32')                                   \n",
    "parser.add_argument('--n_batch_per_epoch', default=2000, type=int, help=\"Number of batch per epochs\")           \n",
    "parser.add_argument('--bn_mode', default=2, type=int, help=\"Batch norm mode\")                                  \n",
    "parser.add_argument('--noise_dim', default=100, type=int, help=\"noise sampler dimension\")                      \n",
    "parser.add_argument('--noise_scale', default=0.5, type=float, help=\"noise sampler variance\")                   \n",
    "parser.add_argument('--disc_iterations', default=5, type=int, help=\"Number of discriminator iterations\")         \n",
    "parser.add_argument('--opt_D', type=str, default=\"Adam\", help=\"Optimizer for the discriminator\")            \n",
    "parser.add_argument('--opt_G', type=str, default=\"Adam\", help=\"Optimizer for the generator\")                \n",
    "parser.add_argument('--lr_D', type=float, default=1E-4, help=\"learning rate for the discriminator\")            \n",
    "parser.add_argument('--lr_G', type=float, default=1-4, help=\"learning rate for the generator\")                \n",
    "parser.add_argument('--use_mbd', action=\"store_true\", help=\"use mini batch disc\")\n",
    "parser.add_argument('--deterministic', action=\"store_true\", help=\"remove the noise input\")\n",
    "parser.add_argument('--inject_noise', action=\"store_true\", help=\"inject noise into each layer\")\n",
    "parser.add_argument('--model', type=str, default=\"lsgan\", help=\"wgan or lsgan\") \n",
    "parser.add_argument('--no_supertrain', action=\"store_true\", help=\"no discriminator supertraining\") \n",
    "parser.add_argument('--pureGAN', action=\"store_true\", help=\"no discriminator supertraining\")\n",
    "parser.add_argument('--lsmooth', type=float, default=1.0, help=\"label smoothing\")\n",
    "parser.add_argument('--monsterClass', action=\"store_true\", help=\"Discriminator with 2x classes\")\n",
    "parser.add_argument('--disc_type', type=str, default=\"simple_disc\", help=\"Discriminator type,between simple_disc or nclass_disc\")\n",
    "parser.add_argument('--resume', action=\"store_true\", help=\"load GAN weights from previous train\")#lsgan_VandWash1 is the name for the run Vand Wash no deterministic, no monsterclass\n",
    "parser.add_argument('--name', type=str, default=\"MnistMtoMnist_dataAug\", help=\"name of the run, used for saving and loading weights\")\n",
    "parser.add_argument('--wd', type=float, default=0.0, help=\"weight decay for generator/discriminator\")\n",
    "parser.add_argument('--history_size', type=float, default=1.8, help=\"history pool size = history_size * batch_size\")\n",
    "parser.add_argument('--data_aug', action=\"store_true\", help=\"perform data augmentation on target dataset\")\n",
    "\n",
    "args = parser.parse_args(' --dset MnistMtoMnist --model lsgan --data_aug --resume --history_size 1.5 --no_supertrain --disc_iterations 1 --wd 1E-5 --lr_D 1E-4 --lr_G 1E-4'.split())\n",
    "######7\n",
    "print args\n",
    "assert args.dset in [\"mnistM\",\"washington_vandal50k\",\"washington_vandal12classes\",\"washington_vandal12classesNoBackground\",\n",
    "                     \"Wash_Vand_12class_LMDB\",\"OfficeDslrToAmazon\",\"bedrooms\",\"Vand_Vand_12class_LMDB\",\"MnistMtoMnist\"]                                                      \n",
    "assert args.opt_G in [\"RMSprop\", \"SGD\", \"Adam\", \"AdamWithWeightnorm\",\"SGDWithWeightnorm\"], \"Unsupported optimizer\"                 \n",
    "assert args.opt_D in [\"RMSprop\", \"SGD\", \"Adam\", \"AdamWithWeightnorm\",\"SGDWithWeightnorm\"], \"Unsupported optimizer\" \n",
    "\n",
    "# Set the backend by modifying the env variable                                                                \n",
    "if args.backend == \"theano\":                                                                                   \n",
    "    os.environ[\"KERAS_BACKEND\"] = \"theano\"                                                                     \n",
    "elif args.backend == \"tensorflow\":                                                                             \n",
    "    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  \n",
    "import keras.backend as K\n",
    "# manually set dim ordering otherwise it is not changed                                                        \n",
    "#if args.backend == \"theano\":                                                                                   \n",
    "#    image_dim_ordering = \"th\"                                                                                  \n",
    "#    K.set_image_dim_ordering(image_dim_ordering)                                                               \n",
    "#elif args.backend == \"tensorflow\":                                                                             \n",
    "image_dim_ordering = \"th\"                                                                                  \n",
    "K.set_image_dim_ordering(image_dim_ordering)\n",
    "\n",
    "# Set default params\n",
    "d_params = {\"generator\": args.generator,\n",
    "            \"discriminator\": args.discriminator,\n",
    "            \"dset\": args.dset,\n",
    "            \"img_dim\": args.img_dim,\n",
    "            \"nb_epoch\": args.nb_epoch,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"n_batch_per_epoch\": args.n_batch_per_epoch,\n",
    "            \"bn_mode\": args.bn_mode,\n",
    "            \"noise_dim\": args.noise_dim,\n",
    "            \"noise_scale\": args.noise_scale,\n",
    "            \"disc_iterations\": args.disc_iterations,\n",
    "            \"lr_D\": args.lr_D,\n",
    "            \"lr_G\": args.lr_G,\n",
    "            \"opt_D\": args.opt_D,\n",
    "            \"opt_G\": args.opt_G,\n",
    "            \"use_mbd\": args.use_mbd,\n",
    "            \"deterministic\": args.deterministic,\n",
    "            \"pureGAN\": args.pureGAN,\n",
    "            \"lsmooth\": args.lsmooth,\n",
    "            \"image_dim_ordering\": image_dim_ordering,\n",
    "            \"model\": args.model,\n",
    "            \"no_supertrain\": args.no_supertrain,\n",
    "            \"monsterClass\": args.monsterClass,\n",
    "            \"data_aug\": args.data_aug,\n",
    "            \"disc_type\": args.disc_type,\n",
    "            \"resume\": args.resume,\n",
    "            \"name\": args.name,\n",
    "            \"inject_noise\": args.inject_noise,\n",
    "            \"history_size\" : args.history_size,\n",
    "            \"wd\" : args.wd\n",
    "            }\n",
    "\n",
    "# Launch training\n",
    "google_BtoA.train(**d_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
